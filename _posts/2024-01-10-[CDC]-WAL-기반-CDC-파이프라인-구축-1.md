---
title: "[CDC] WAL 기반 CDC 파이프라인 구축 (1)"
excerpt: "Change Data Capture의 개념과 WAL 로그 기반 파이프라인 구축 방법"

categories:
  - Data
tags:
  - [Data]

permalink: /data/[CDC]-WAL-기반-CDC-파이프라인-구축-1/

toc: true
toc_sticky: true

date: 2024-01-10
last_modified_at: 2024-01-21
---

## CDC(Change Data Capture)의 개념
![image](https://github.com/zisu17/zisu17/assets/108858121/428a853a-28da-4071-8e0c-9bea1212535a)

CDC는 데이터 변경사항을 추적하고 이 변경사항에 대해 필요한 후속 처리를 자동화하는 기술이다. 
소스 시스템 데이터의 변경을 감지하여 타겟 시스템에 실시간에 근접한 속도로 통합이 가능하고 데이터 복제, 백업, 분석, 실시간 대시보드 업데이트 등 다양한 용도로 활용할 수 있다. 

예를 들어 사용자 행동 로그에 따라 실시간으로 데이터를 분석해 상품을 추천하는 서비스를 만들고 싶을 때 CDC를 활용하면 운영 시스템의 데이터 변화에 따라 분석용 데이터베이스를 빠르게 구축할 수 있는 것이다. 
특히 차차 공부하며 실습할 WAL 로그 기반 CDC를 활용하면 운영 시스템에 큰 부하없이 빠른 통합이 가능해진다. 

## CDC 구현 방식
CDC 구현 방식은 크게 Query-Based 방식과 Log-Based 방식 이 두 가지로 나뉜다. 
Query-Based 방식은 타겟 시스템이 소스 시스템의 데이터를 주기적으로 조회하여 변경사항을 감지하는 방식이고 
Log-Based 방식은 데이터베이스의 트랜잭션 로그나 Write-Ahead Logging (WAL)을 활용하여 데이터 변경을 감지하는 방식이다.

### Query-Based (Pull) 방식
**장점**  
- 쿼리를 사용해 데이터를 끌어오는 방식은 일반적인 데이터 접근 방식과 비슷해서 개발 및 유지보수가 상대적으로 간단하다.
- 쿼리를 사용하기 때문에 특별한 로깅 메커니즘이 필요하지 않고 대부분의 데이터베이스 시스템에서 호환된다.

**단점**  
- 데이터를 주기적으로 폴링하기 때문에 실시간 데이터 동기화에는 적합하지않다.
- 주기적으로 쿼리를 날려 데이터 변경사항을 체크하기 때문에 소스시스템에 부하를 줄 수 있다.

### Log-Based (Push) 방식

**장점**  
- 로그 파일에 기록된 변경사항을 거의 실시간으로 타겟 시스템에 전송할 수 있다.
- 로그 파일을 읽는 방식이기 때문에 소스 데이터베이스에 부하를 거의 주지 않는다.
- 데이터 삽입, 수정, 삭제 등 모든 유형의 데이터 변경을 정확하게 캡처할 수 있다.

**단점**  
- 데이터베이스가 내부 로그 파일을 처리하는 방식에 대한 기술적인 이해가 필요하다.
- 로그를 푸시하는 방식이기 때문에 타겟 시스템에 문제가 발생하면 데이터가 누락될 수 있는 위험이 있다.
- 특정 데이터베이스의 로그 형식에 종속되기 때문에 모든 데이터베이스에서 사용할 수 있는 것은 아니다.

CDC를 구현할 땐 시스템 부하, 데이터베이스 환경, 기술적 복잡성, 데이터를 얼마나 실시간으로 반영해야 하는지 등을 고려하여 선택하게 되는데 
이번에는 Log-Based 방식을 활용하여 CDC를 구현 해볼 예정이다. 

### Kafka를 활용한 CDC 구현
#### Kafka의 역할
![image](https://github.com/zisu17/zisu17/assets/108858121/e2d52ff8-4250-4353-9c28-6872c432ff9e)

앞서 말했듯 Log-Based 방식은 타겟 시스템에 문제가 발생하면 데이터 변경사항이 누락될 위험이 있다. 
이때 Kafka를 활용하면 타겟 시스템에 문제 발생했을 때도 해당 offset부터 이벤트를 다시 읽어오면 되기 때문에 누락 문제를 보완할 수 있다.

#### 구현 방법
**1. Kafka 구성 및 실행**  
첫번째 단계는 Zookeeper 서버와 Kafka 브로커를 시작한다. Zookeeper는 시스템의 분산 특성을 관리하는데 도움이 되고
Kafka 브로커는 프로듀서로부터 메시지를 받고 메시지에 오프셋을 할당하며 디스크 저장소에 커밋하는 역할을 담당한다.

**2. Debezium 설치**  
다음으로 Debezium을 설치한다. 다른 설치 옵션도 있지만 Kafka Connect를 사용하는 것이 좋다.

**3. Debezium 커넥터 구성**  
데이터베이스 호스트, 포트, 사용자 이름, 비밀번호, 데이터베이스 서버 ID 등 필요한 세부 정보로 커넥터를 구성하고
Kafka Connect 클래스 경로에 Debezium 커넥터 jar 파일을 포함하여 Kafka Connect에 커넥터를 등록한다.

**4. Change Data Capture**  
커넥터 구성 후 등록이 완료되면 데이터베이스 변경 내용을 기록하는 WAL 로그 모니터링이 시작된다.
데이터베이스가 변경되면 커넥터가 변경 이벤트를 생성하도록 트리거된다.

**5. 변경 이벤트를 Kafka로 스트리밍**  
Debezium 커넥터로 생성된 데이터베이스 변경 이벤트는 Kafka 소스 테이블명으로 전송된다.
이벤트는 키밸류 형태로 구성되며 Kafka Connect Converter를 사용해 이진형식으로 직렬화된다.

**6. 다운스트림 Consumer 생성**  
Kafka 토픽에서 데이터를 찾아 타겟 시스템(RDBMS, DW, DL 등)에 저장하도록 다운스트림 Consumer를 설정한다.

**7. 성능 최적화**  
CDC 설정을 최적화하려면 Kafka 및 Debezium 설정의 성능 및 리소스 활용도를 기반으로
배치 크기, 폴링 간격, 버퍼 크기 등의 매개변수들을 조정한다.

**8. 모니터링 및 유지 관리**  
시스템 상태를 체크하며 대기시간, 처리량, 오류율 등의 항목들을 모니터링한다.
정기적인 점검을 위한 로그 파일 확인, 백업 확인, 리소스 사용량 모니터링이 가능하도록 구성한다.

