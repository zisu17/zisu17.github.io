---  
title: "[Kafka] 카프카 데이터 처리 병목 문제해결"  
excerpt: "스파크 스트리밍 어플리케이션의 파티션 기반 구독 방식 적용 사례"  
  
categories:  
  - Data  
tags:  
  - [Data]  
permalink: /data/[Kafka]-카프카-데이터-처리-병목-문제해결/  
  
toc: true  
toc_sticky: true  
  
date: 2024-07-28  
last_modified_at: 2024-07-28  
---  
  
## 스트리밍 처리에서의 문제점
**이슈 내용**  
데이터를 수집할 때 카프카와 스파크 스트리밍을 사용하여 실시간 처리하는 파이프라인 구조는 데이터 파이프라인에서 자주 볼 수 있는 구조이다. 
여기서 생길 수 있는 문제점이 아래와 같이 데이터를 가공하는 속도가 수집하는 속도를 따라가지 못하여 적재가 밀리는 현상이 발생할 수 있다는 것이다. 
이번 글은 카프카 스파크 스트리밍 구조에서 카프카 컨슈밍 방식을 변경하여 데이터 처리 병목을 해결하는 내용에 대해서 담을 예정이다. 

![img.png](/assets/images/2024-07-28-[Kafka]-카프카-데이터-처리-병목-문제해결/Pasted image 20240809171802.png)

위 이미지를 보면 실시간 처리되어야 하는 데이터들이 밀리면서 2~3시간의 공백이 발생하는 것을 볼 수 있다. 

![img.png](/assets/images/2024-07-28-[Kafka]-카프카-데이터-처리-병목-문제해결/Pasted image 20240809173222.png)

실제 카프카 토픽은 위와 같이 계속하여 데이터가 쌓이고 있다. 
  
**해결 내용**  
- 해당 데이터를 구독하는 스파크 스트리밍 어플리케이션을 추가로 생성하여 하나의 토픽을 여러개의 어플리케이션이 처리하도록 수정한다. 
- 카프카 토픽의 구독 방식 변경    
`.option("subscribe", 'landing_blog_cafe')` : 하나의 스파크 스트리밍 어플리케이션이 해당 카프카 토픽에 있는 모든 파티션을 구독    
`.option("assign", '{"landing_blog_cafe":[0, 1]}'`) : 해당 카프카 토픽에 있는 특정 파티션을 구독  
- 변경시 기존 offset을 사용하지 않고 처음부터 다시 컨슈밍하게 되므로 해당 부분 주의 필요  
- assign 옵션으로 2개의 스파크 어플리케이션이 파티션을 분리하여 컨슈밍할 수 있도록 수정  
  

기존의 스파크 스트리밍 방식은 아래와 같이 하나의 어플리케이션을 실행하여 한 컨슈머로 토픽의 모든 파티션을 subscribe 하도록 설계되어 있다.  
```  
df_before = spark \    
    .readStream \    
    .format("kafka") \    
    .option("kafka.bootstrap.servers", kafka_bootstrap_servers) \    
    .option("maxOffsetsPerTrigger", 100) \    
    .option("startingOffsets", "latest") \    
    .option("failOnDataLoss", "false") \    
    .option("subscribe", "topic_name") \    
    .option("kafka.group.id", "group_a") \    
    .load()  
```  

아래와 같이 두 개의 어플리케이션으로 파티션을 분리해 구독하도록 수정하였다.  
```  
df_after = spark \    
    .readStream \    
    .format("kafka") \    
    .option("kafka.bootstrap.servers", kafka_bootstrap_servers) \    
    .option("maxOffsetsPerTrigger", 100) \    
    .option("startingOffsets", "latest") \    
    .option("failOnDataLoss", "false") \    
    .option("assign", "{'topic_name': [2, 3]}") \    
    .load()  
```  

해당 토픽의 데이터가 도큐먼트 하나 당 용량이 크기 때문에 감성 분석 처리하는데에 시간이 많이 걸렸다. 토픽을 두 개의 컨슈머가 구독하여 처리하기 때문에 아래와 같이 밀리지 않고 정상적으로 데이터가 처리되는 것을 볼 수 있다.  

![img.png](/assets/images/2024-07-28-%5BKafka%5D-카프카-데이터-처리-병목-문제해결/img.png)
  
## 처음 시도한 방식  
  
- 2개의 스파크 어플리케이션에서 동일한 그룹 아이디를 사용하려고 했으나 오류 발생  
- 서로 다른 그룹 아이디를 할당했을때는 중복 컨슈밍 문제 발생  
- 기존 카프카 토픽의 파티션을 4개로 줄이고 각 스파크 애플리케이션에 0,1 / 2,3 파티션 번호를 할당했으나 이전에 5개 파티션일 때 존재했던 4번 파티션을 읽으려고 시도하다가 오류가 발생함    
→ 기존에 사용하던 체크포인트를 그대로 사용하여 문제 발생한 것으로 추정 checkpointLocation 폴더 삭제후 재가동하니 정상 작동 확인 완료  
  
```  
org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before the position for partition landing_blog_cafe - 4 could be determined  
```